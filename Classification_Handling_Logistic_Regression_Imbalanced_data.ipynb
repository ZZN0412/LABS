{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the required libraries and modules that you would need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1626256792304,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -120
    },
    "id": "sS-WVW_mQmAu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read that data into Python and call the dataframe churnData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    churnData = pd.read_csv(\"Data/DATA_Customer-Churn.csv\")\n",
    "    return churnData\n",
    "churnData = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the datatypes of all the columns in the data. You would see that the column TotalCharges is object type. Convert this column into numeric type using pd.to_numeric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numeric(churnData):\n",
    "    churnData['TotalCharges'] = pd.to_numeric(churnData['TotalCharges'], errors='coerce')\n",
    "    return churnData\n",
    "churnData = convert_to_numeric(churnData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check for null values in the dataframe. Replace the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(churnData.isna().sum()/len(churnData),4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_null_values(churnData):\n",
    "    mean_TotalCharges = np.mean(churnData['TotalCharges'])\n",
    "    churnData['TotalCharges'] = churnData['TotalCharges'].fillna(mean_TotalCharges)\n",
    "    return churnData\n",
    "churnData = replace_null_values(churnData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(churnData.isna().sum()/len(churnData),4)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the following features: tenure, SeniorCitizen, MonthlyCharges and TotalCharges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(churnData):\n",
    "    churnData_features = churnData.drop(columns=['gender','Partner','Dependents',\n",
    "                                                  'PhoneService','OnlineSecurity',\n",
    "                                                  'OnlineBackup','DeviceProtection',\n",
    "                                                  'TechSupport','StreamingTV',\n",
    "                                                  'StreamingMovies','Contract'])\n",
    "    return churnData_features\n",
    "churnData_features = drop_columns(churnData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_coding_categorical_variables(churnData_features):\n",
    "    categoricals_features= churnData_features.select_dtypes(\"object\")\n",
    "    print(categoricals_features)\n",
    "    \n",
    "    categoricals_features=pd.get_dummies(categoricals_features[['Churn']], drop_first=True)\n",
    "    print(categoricals_features)\n",
    "    \n",
    "    #adding categorical features\n",
    "    churnData_features = pd.concat([churnData_features,categoricals_features],axis=1)\n",
    "    return churnData_features\n",
    "churnData_features = hot_coding_categorical_variables(churnData_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_x_y(churnData_features):\n",
    "    X = churnData_features.drop(columns=['Churn','Churn_Yes'], axis = 1)\n",
    "    y = churnData_features['Churn_Yes']\n",
    "    return X, y\n",
    "X,y = define_x_y(churnData_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the data into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitting(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "    X_test  = pd.DataFrame(X_test, columns=X.columns)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = data_splitting(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scale the features either by using normalizer or a standard scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit a logistic Regression model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(X_train, X_test):\n",
    "\n",
    "    trans = PowerTransformer() # The same as standard scaler\n",
    "\n",
    "    trans.fit(X_train)\n",
    "\n",
    "    X_train_mod = trans.transform(X_train)\n",
    "    X_test_mod  = trans.transform(X_test)\n",
    "\n",
    "    log_model = LogisticRegression() \n",
    "    \n",
    "    log_model.fit(X_train_mod, y_train)\n",
    "\n",
    "    y_pred_train_log = log_model.predict(X_train_mod)\n",
    "    y_pred_test_log = log_model.predict(X_test_mod)\n",
    "\n",
    "    performance_log = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_log),\n",
    "                                         precision_score(y_train, y_pred_train_log),\n",
    "                                         recall_score(y_train, y_pred_train_log)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_log),\n",
    "                                        precision_score(y_test, y_pred_test_log),\n",
    "                                        recall_score(y_test, y_pred_test_log)]})\n",
    "    display(performance_log)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Confusion matrix for the train set\")\n",
    "    print(confusion_matrix(y_train,y_pred_train_log))\n",
    "    plot_confusion_matrix(log_model,X_train_mod,y_train, values_format = 'd')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Confusion matrix for the test set\")\n",
    "    print(confusion_matrix(y_test, y_pred_test_log))\n",
    "    plot_confusion_matrix(log_model,X_test_mod,y_test, values_format = 'd')\n",
    "    plt.show()\n",
    "    \n",
    "    return performance_log, y_pred_train_log, y_pred_test_log\n",
    "performance_log, y_pred_train_log, y_pred_test_log = logistic_regression_model(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit a Knn Classifier model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier_model (X_train, X_test):\n",
    "\n",
    "    trans = PowerTransformer()\n",
    "\n",
    "    trans.fit(X_train)\n",
    "\n",
    "    X_train_mod = trans.transform(X_train)\n",
    "    X_test_mod  = trans.transform(X_test)\n",
    "\n",
    "    neigh = KNeighborsClassifier() #Import KNeighborsClassifier to use the K-NN for classification\n",
    "    \n",
    "    neigh.fit(X_train_mod, y_train)\n",
    "\n",
    "    y_pred_train_knn = neigh.predict(X_train_mod)\n",
    "    y_pred_test_knn = neigh.predict(X_test_mod)\n",
    "\n",
    "    performance_knn = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_knn),\n",
    "                                         precision_score(y_train, y_pred_train_knn),\n",
    "                                         recall_score(y_train, y_pred_train_knn)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_knn),\n",
    "                                        precision_score(y_test, y_pred_test_knn),\n",
    "                                        recall_score(y_test, y_pred_test_knn)]})\n",
    "    display(performance_knn)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Confusion matrix for the train set\")\n",
    "    print(confusion_matrix(y_train,y_pred_train_knn))\n",
    "    plot_confusion_matrix(neigh,X_train_mod,y_train, values_format = 'd')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Confusion matrix for the test set\")\n",
    "    print(confusion_matrix(y_test, y_pred_test_knn))\n",
    "    plot_confusion_matrix(neigh, X_test_mod, y_test, values_format = 'd')\n",
    "    plt.show()\n",
    "    \n",
    "    return performance_knn, neigh\n",
    "performance_knn, neigh= knn_classifier_model(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit a Decision Tree Classifier on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_classifier_model (X_train, X_test):\n",
    "\n",
    "    # Bear in mind that sklearn uses a different function for decission trees used for \n",
    "    # classification (to predict a categorical feature): DecisionTreeClassifier() \n",
    "    dt = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train_dt = dt.predict(X_train)\n",
    "    y_pred_test_dt = dt.predict(X_test)\n",
    "\n",
    "    performance_df = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_dt),\n",
    "                                         precision_score(y_train, y_pred_train_dt),\n",
    "                                         recall_score(y_train, y_pred_train_dt)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_dt),\n",
    "                                        precision_score(y_test, y_pred_test_dt),\n",
    "                                        recall_score(y_test, y_pred_test_dt)]})\n",
    "    display(performance_df)\n",
    "\n",
    "    print(\"Confusion matrix for the train set\")\n",
    "    print(confusion_matrix(y_train,y_pred_train_dt).T)\n",
    "    plot_confusion_matrix(dt,X_train,y_train, values_format = 'd')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Confusion matrix for the test set\")\n",
    "    print(confusion_matrix(y_test,y_pred_test_dt).T)\n",
    "    plot_confusion_matrix(dt,X_test,y_test, values_format = 'd')\n",
    "    plt.show()\n",
    "    \n",
    "    return dt, performance_df, y_pred_train_dt, y_pred_test_dt\n",
    "dt, performance_df, y_pred_train_dt, y_pred_test_dt = decision_tree_classifier_model (X_train, X_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes= plt.subplots(nrows= 1, ncols= 1, figsize= (34, 20))\n",
    "\n",
    "plot_tree(dt, filled=True, rounded= True, feature_names= X.columns)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apply K-fold cross validation on your models before and check the model score. Note: So far we have not balanced the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models Comparison\n",
    "model1 = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "model2 = LogisticRegression() \n",
    "\n",
    "model3 = KNeighborsClassifier()\n",
    "\n",
    "model_pipeline = [model1, model2, model3]\n",
    "model_names = ['Regression Tree', 'Logistic Regression', 'KNN']\n",
    "scores = {}\n",
    "i=0\n",
    "for model in model_pipeline:\n",
    "    mean_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "    scores[model_names[i]] = mean_score\n",
    "    i = i+1\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing imbalance in the dataset\n",
    "Check for the imbalance. Use the resampling strategies used in class for upsampling and downsampling to create a balance between the two classes. Each time fit the model and see how the accuracy of the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_0 = churnData_features[churnData_features['Churn_Yes'] == 0]\n",
    "category_1 = churnData_features[churnData_features['Churn_Yes'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_0.shape)\n",
    "print(category_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_0_down = category_0.sample(len(category_1,))\n",
    "print(category_0_down.shape)\n",
    "print(category_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData_features = pd.concat([category_0_down, category_1], axis=0)\n",
    "#shuffling the data\n",
    "churnData_features = churnData_features.sample(frac=1)\n",
    "churnData_features['Churn_Yes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_0 = churnData_features[churnData_features['Churn_Yes'] == 0]\n",
    "category_1 = churnData_features[churnData_features['Churn_Yes'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_1_up = category_1.sample(len(category_0), replace=True)\n",
    "print(category_1_up.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_1_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_1_up.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData_features = pd.concat([category_0, category_1_up], axis=0)\n",
    "#shuffling the data\n",
    "churnData_features = churnData_features.sample(frac=1)\n",
    "churnData_features['Churn_Yes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(X_train, X_test):\n",
    "\n",
    "    trans = PowerTransformer() # The same as standard scaler\n",
    "\n",
    "    trans.fit(X_train)\n",
    "\n",
    "    X_train_mod = trans.transform(X_train)\n",
    "    X_test_mod  = trans.transform(X_test)\n",
    "\n",
    "    log_model = LogisticRegression() \n",
    "    \n",
    "    log_model.fit(X_train_mod, y_train)\n",
    "\n",
    "    y_pred_train_log = log_model.predict(X_train_mod)\n",
    "    y_pred_test_log = log_model.predict(X_test_mod)\n",
    "\n",
    "    performance_log = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_log),\n",
    "                                         precision_score(y_train, y_pred_train_log),\n",
    "                                         recall_score(y_train, y_pred_train_log)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_log),\n",
    "                                        precision_score(y_test, y_pred_test_log),\n",
    "                                        recall_score(y_test, y_pred_test_log)]})\n",
    "    display(performance_log)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Confusion matrix for the train set\")\n",
    "    print(confusion_matrix(y_train,y_pred_train_log))\n",
    "    plot_confusion_matrix(log_model,X_train_mod,y_train, values_format = 'd')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Confusion matrix for the test set\")\n",
    "    print(confusion_matrix(y_test, y_pred_test_log))\n",
    "    plot_confusion_matrix(log_model,X_test_mod,y_test, values_format = 'd')\n",
    "    plt.show()\n",
    "    \n",
    "    return performance_log, y_pred_train_log, y_pred_test_log\n",
    "performance_log, y_pred_train_log, y_pred_test_log = logistic_regression_model(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier_model (X_train, X_test):\n",
    "\n",
    "    trans = PowerTransformer()\n",
    "\n",
    "    trans.fit(X_train)\n",
    "\n",
    "    X_train_mod = trans.transform(X_train)\n",
    "    X_test_mod  = trans.transform(X_test)\n",
    "\n",
    "    neigh = KNeighborsClassifier() #Import KNeighborsClassifier to use the K-NN for classification\n",
    "    \n",
    "    neigh.fit(X_train_mod, y_train)\n",
    "\n",
    "    y_pred_train_knn = neigh.predict(X_train_mod)\n",
    "    y_pred_test_knn = neigh.predict(X_test_mod)\n",
    "\n",
    "    performance_knn = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_knn),\n",
    "                                         precision_score(y_train, y_pred_train_knn),\n",
    "                                         recall_score(y_train, y_pred_train_knn)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_knn),\n",
    "                                        precision_score(y_test, y_pred_test_knn),\n",
    "                                        recall_score(y_test, y_pred_test_knn)]})\n",
    "    display(performance_knn)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Confusion matrix for the train set\")\n",
    "    print(confusion_matrix(y_train,y_pred_train_knn))\n",
    "    plot_confusion_matrix(neigh,X_train_mod,y_train, values_format = 'd')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Confusion matrix for the test set\")\n",
    "    print(confusion_matrix(y_test, y_pred_test_knn))\n",
    "    plot_confusion_matrix(neigh, X_test_mod, y_test, values_format = 'd')\n",
    "    plt.show()\n",
    "    \n",
    "    return performance_knn, neigh\n",
    "performance_knn, neigh= knn_classifier_model(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_classifier_model (X_train, X_test):\n",
    "\n",
    "    # Bear in mind that sklearn uses a different function for decission trees used for \n",
    "    # classification (to predict a categorical feature): DecisionTreeClassifier() \n",
    "    dt = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train_dt = dt.predict(X_train)\n",
    "    y_pred_test_dt = dt.predict(X_test)\n",
    "\n",
    "    performance_df = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_dt),\n",
    "                                         precision_score(y_train, y_pred_train_dt),\n",
    "                                         recall_score(y_train, y_pred_train_dt)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_dt),\n",
    "                                        precision_score(y_test, y_pred_test_dt),\n",
    "                                        recall_score(y_test, y_pred_test_dt)]})\n",
    "    display(performance_df)\n",
    "\n",
    "    print(\"Confusion matrix for the train set\")\n",
    "    print(confusion_matrix(y_train,y_pred_train_dt).T)\n",
    "    plot_confusion_matrix(dt,X_train,y_train, values_format = 'd')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Confusion matrix for the test set\")\n",
    "    print(confusion_matrix(y_test,y_pred_test_dt).T)\n",
    "    plot_confusion_matrix(dt,X_test,y_test, values_format = 'd')\n",
    "    plt.show()\n",
    "    \n",
    "    return dt, performance_df, y_pred_train_dt, y_pred_test_dt\n",
    "dt, performance_df, y_pred_train_dt, y_pred_test_dt = decision_tree_classifier_model (X_train, X_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes= plt.subplots(nrows= 1, ncols= 1, figsize= (34, 20))\n",
    "\n",
    "plot_tree(dt, filled=True, rounded= True, feature_names= X.columns)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=cross_val_score(dt, X_train, y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%0.9f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(dt, X_test, y_test, cv=5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models Comparison\n",
    "model1 = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "model2 = LogisticRegression() \n",
    "\n",
    "model3 = KNeighborsClassifier()\n",
    "\n",
    "model_pipeline = [model1, model2, model3]\n",
    "model_names = ['Regression Tree', 'Logistic Regression', 'KNN']\n",
    "scores = {}\n",
    "i=0\n",
    "for model in model_pipeline:\n",
    "    mean_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "    scores[model_names[i]] = mean_score\n",
    "    i = i+1\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN5a07AzJeFSAhhaVwEynaA",
   "name": "Code-along.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
